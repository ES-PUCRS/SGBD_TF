{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------ HandBook ------------------------\n",
    "#     \tLegenda do resumo\n",
    "# #!# \t= Atribuição ao X\n",
    "# #*# \t= Ação manual necessária\n",
    "# ###!\t= Observações das escolhas no passo\n",
    "# #!\t= Observação para a execução do passo\n",
    "\n",
    "## 1. Importar bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#*# 2. Importar dataset\n",
    "#! com pasta 'database/file.csv'\n",
    "file = '.csv'\t\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "## 3. Analise exploratória de dados\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "#*# 3.1. Agrupando atributos (facilita a vida)\n",
    "atributos_X \t\t = [] # preenchido no passo 5.5\n",
    "atributos_preditivos = [] # preenchido no passo 4\n",
    "atributo_alvo\t\t = ''\n",
    "atributos    \t\t = []\n",
    "atributos_numericos\t = [] \n",
    "atributos_binarios\t = []\n",
    "atributos_nominais\t = []\n",
    "atributos_enum\t\t = []\n",
    "\n",
    "## 4. Resolvendo valores ausentes\n",
    "atrb_na = []\n",
    "###! Remove linha nula\n",
    "#df_treino.dropna(subset=atrb_na)\n",
    "###! Remove coluna nula\n",
    "#df_treino.drop(atrib_na, axis=1)\n",
    "###! Procura o valor para preencher linhas com valor nulo\n",
    "#! strategy : string, default='mean'\n",
    "#!    - If \"mean\", then replace missing values using the mean along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\n",
    "#!    - If \"median\", then replace missing values using the median along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\tUse when the values are smoothly distributed\n",
    "#!\n",
    "#!    - If \"most_frequent\", then replace missing using the most frequent\n",
    "#!      value along each column. Can be used with strings or numeric data.\n",
    "#!\n",
    "#!    - If \"constant\", then replace missing values with fill_value. Can be\n",
    "#!      used with strings or numeric data.\n",
    "#estrategia\t  = 'mean'\n",
    "#imputer = SimpleImputer(strategy='estrategia')\n",
    "#novos_valores = imputer.fit_transform(df_treino[atrb_na])\n",
    "\n",
    "## 4.1. Calculando as correlações entre os atributos\n",
    "atributos_preditivos = atributos_numericos\n",
    "atributos_preditivos = np.append(atributos_preditivos, atributos_enum)\n",
    "corr = np.corrcoef(df[atributos_preditivos],rowvar=False)\n",
    "dfcorr = pd.DataFrame(corr,index=atributos_preditivos,columns=atributos_preditivos)\n",
    "dfcorr.to_csv('correlmat.csv',sep=';',decimal=',')\n",
    "\n",
    "#*# 4.2. Listando atributos desnecessários\n",
    "#! Atributo com valor muito próximos de 1 do passo acima.\n",
    "#! + Atributos irrelevantes para o aprendizado\n",
    "atributos_desnecessarios = []\n",
    "\n",
    "## 5. Pré-processamento\n",
    "df_treino, df_teste = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "## 5.1. Separando o atributo alvo dos preditivos\n",
    "df_treino_labels = df_treino[atributo_alvo].copy()\n",
    "df_treino        = df_treino.drop(columns=atributo_alvo)\n",
    "\n",
    "## 5.2. (+> 4.1) Removendo atributos desnecessários\n",
    "df_treino = df_treino.drop (columns=atributos_desnecessarios)\n",
    "df_teste  = df_teste.drop  (columns=atributos_desnecessarios)\n",
    "\n",
    "#*# Resolvendo valores ausentes\n",
    "#! Antecipado ao passo 4 para poder exportar Pearson\n",
    "\n",
    "## 5.3. Ajustando a escala dos atributos numéricos quantitativos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_treino[atributos_numericos])\n",
    "\n",
    "#!# 5.4. Populando o X_treino com colunas numericas\n",
    "X = scaler.transform(df_treino[atributos_numericos])\n",
    "atributos_X = atributos_numericos\n",
    "\n",
    "#!# 5.5. Populando o X_treino com colunas binárias\n",
    "X = np.concatenate((X, df_treino[atributos_binarios]),axis=1)\n",
    "atributos_X = np.append(atributos_X, atributos_binarios)\n",
    "\n",
    "#!# 5.6. Binarizando atributos categóricos\n",
    "for atrb_name in atributos_enum:\n",
    "\t# binarizando a coluna de nome atrb_name\n",
    "\tlb = LabelBinarizer()\n",
    "\tdados = lb.fit_transform(df_treino[atrb_name].values)\n",
    "    \n",
    "\t# acrescentando a matriz com as novas colunas na matriz X\n",
    "\tX = np.concatenate((X, dados),axis=1)\n",
    "    \n",
    "\t# criando nomes para as novas colunas no seguinte formato: nome_do_atributo=valor_do_atributo\n",
    "\tnomes_novos_atributos = []\n",
    "\tfor class_name in lb.classes_:\n",
    "\t\tnomes_novos_atributos = np.append(nomes_novos_atributos,atrb_name+'='+str(class_name))\n",
    "        \n",
    "\t# acrescentando os nomes das novas colunas na lista completa do dataset\n",
    "\tatributos_X = np.append(atributos_X, nomes_novos_atributos)\n",
    "    \n",
    "\t# Debug da transformação de num para enum\n",
    "\t# print('Nome do atributo categórico: ',atrb_name)\n",
    "\t# print('Classes aprendidas: ',lb.classes_)\n",
    "\t# print('Nomes dos novos atributos: ',nomes_novos_atributos)\n",
    "\t# print(\"Primeiras 5 linhas dos dados: \")\n",
    "\t# print(dados[0:5,])\n",
    "\t# print()\n",
    "\n",
    "## 6. Visualização do resultado do pré-processamento\n",
    "df_treino_preproc = pd.DataFrame(X, columns=atributos_X)\n",
    "df_treino_preproc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importando DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! com pasta 'database/file.csv'\n",
    "datasetFolder = 'database/'\n",
    "file = datasetFolder + 'data.csv'\n",
    "df = pd.read_csv(file)\n",
    "dataset = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Primeira analise do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11500 entries, 0 to 11499\n",
      "Columns: 180 entries, Unnamed: 0 to y\n",
      "dtypes: int64(179), object(1)\n",
      "memory usage: 15.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. Analise exploratória de dados\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Analise exploratória - Agrupando atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_X          = [] # Preenchido no passo 5.5\n",
    "atributos_preditivos = [] # Usado no passo 4\n",
    "\n",
    "#Definindo os atributos\n",
    "atributo_alvo        = 'y'\n",
    "atributos_desnecessarios = ['Unnamed: 0']\n",
    "atributos_numericos  = list( x for x in dataset.columns if x not in atributos_desnecessarios )\n",
    "atributos_binarios   = []\n",
    "atributos_nominais   = []\n",
    "atributos_enum       = []\n",
    "\n",
    "#Removendo o atributo alvo das variáveis de pesquisa\n",
    "atributos_numericos  = [ x for x in atributos_numericos if x is not atributo_alvo ]\n",
    "atributos_binarios   = [ x for x in atributos_binarios if x is not atributo_alvo ]\n",
    "atributos_nominais   = [ x for x in atributos_nominais if x is not atributo_alvo ]\n",
    "atributos_enum       = [ x for x in atributos_enum if x is not atributo_alvo ]\n",
    "\n",
    "# Reunindo atributos\n",
    "atributos            = atributos_numericos\n",
    "atributos            = np.append(atributos, atributos_binarios)\n",
    "atributos            = np.append(atributos, atributos_nominais)\n",
    "atributos            = np.append(atributos, atributos_enum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resolvendo valores ausentes e/ou desnecessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atrb_na = ['']2\n",
    "###! Remove linha nula\n",
    "# df = df.dropna(subset=atrb_na)\n",
    "###! Remove coluna nula\n",
    "df = df.drop(atributos_desnecessarios, axis=1)\n",
    "###! Procura o valor para preencher linhas com valor nulo\n",
    "#! strategy : string, default='mean'\n",
    "#!    - If \"mean\", then replace missing values using the mean along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\n",
    "#!    - If \"median\", then replace missing values using the median along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\tUse when the values are smoothly distributed\n",
    "#!\n",
    "#!    - If \"most_frequent\", then replace missing using the most frequent\n",
    "#!      value along each column. Can be used with strings or numeric data.\n",
    "#!\n",
    "#!    - If \"constant\", then replace missing values with fill_value. Can be\n",
    "#!      used with strings or numeric data.\n",
    "#estrategia\t  = 'mean'\n",
    "#imputer = SimpleImputer(strategy=estrategia)\n",
    "#novos_valores = imputer.fit_transform(df_treino[atrb_na])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Calculando as correlações entre os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de atributos preditivos:  178 .\n",
      "Lista dos atributos preditivos: ['X1' 'X2' 'X3' 'X4' 'X5' 'X6' 'X7' 'X8' 'X9' 'X10' 'X11' 'X12' 'X13'\n",
      " 'X14' 'X15' 'X16' 'X17' 'X18' 'X19' 'X20' 'X21' 'X22' 'X23' 'X24' 'X25'\n",
      " 'X26' 'X27' 'X28' 'X29' 'X30' 'X31' 'X32' 'X33' 'X34' 'X35' 'X36' 'X37'\n",
      " 'X38' 'X39' 'X40' 'X41' 'X42' 'X43' 'X44' 'X45' 'X46' 'X47' 'X48' 'X49'\n",
      " 'X50' 'X51' 'X52' 'X53' 'X54' 'X55' 'X56' 'X57' 'X58' 'X59' 'X60' 'X61'\n",
      " 'X62' 'X63' 'X64' 'X65' 'X66' 'X67' 'X68' 'X69' 'X70' 'X71' 'X72' 'X73'\n",
      " 'X74' 'X75' 'X76' 'X77' 'X78' 'X79' 'X80' 'X81' 'X82' 'X83' 'X84' 'X85'\n",
      " 'X86' 'X87' 'X88' 'X89' 'X90' 'X91' 'X92' 'X93' 'X94' 'X95' 'X96' 'X97'\n",
      " 'X98' 'X99' 'X100' 'X101' 'X102' 'X103' 'X104' 'X105' 'X106' 'X107'\n",
      " 'X108' 'X109' 'X110' 'X111' 'X112' 'X113' 'X114' 'X115' 'X116' 'X117'\n",
      " 'X118' 'X119' 'X120' 'X121' 'X122' 'X123' 'X124' 'X125' 'X126' 'X127'\n",
      " 'X128' 'X129' 'X130' 'X131' 'X132' 'X133' 'X134' 'X135' 'X136' 'X137'\n",
      " 'X138' 'X139' 'X140' 'X141' 'X142' 'X143' 'X144' 'X145' 'X146' 'X147'\n",
      " 'X148' 'X149' 'X150' 'X151' 'X152' 'X153' 'X154' 'X155' 'X156' 'X157'\n",
      " 'X158' 'X159' 'X160' 'X161' 'X162' 'X163' 'X164' 'X165' 'X166' 'X167'\n",
      " 'X168' 'X169' 'X170' 'X171' 'X172' 'X173' 'X174' 'X175' 'X176' 'X177'\n",
      " 'X178']\n"
     ]
    }
   ],
   "source": [
    "# Prepara os atributos não String\n",
    "atributos_preditivos = atributos_numericos\n",
    "atributos_preditivos = np.append(atributos_preditivos, atributos_enum)\n",
    "\n",
    "print (\n",
    "    'Quantidade de atributos preditivos: ',\n",
    "        atributos_preditivos.size,\n",
    "    '.\\nLista dos atributos preditivos:',\n",
    "        atributos_preditivos)\n",
    "\n",
    "# Correlação de Pearson\n",
    "corr = np.corrcoef(df[atributos_preditivos],rowvar=False)\n",
    "\n",
    "# Tabularização das informações\n",
    "dfcorr = pd.DataFrame(corr,index=atributos_preditivos,columns=atributos_preditivos)\n",
    "\n",
    "# Exporta para csv\n",
    "dfcorr.to_csv('correlmat.csv',sep=';',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_numericos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
